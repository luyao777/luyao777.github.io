[{"section":"Blog","slug":"/blog/post-3/","title":"解析 tensoflow 预热文件","description":"this is meta description","date":"February 26, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"Tensorflow","tags":"Tensorflow","content":"解析 tensoflow 预热文件 代码如下：\n注意，这里 tf_record_iterator 要使用最新的 api, 比如这里 tf2.5 使用的是 tf.compat.v1.io.tf_record_iterator。\nimport tensorflow as tf from tensorflow_serving.apis import prediction_log_pb2 def par_warmup(): i = 0 for serialized_example in tf.compat.v1.io.tf_record_iterator(\u0026#34;./assets.extra/tf_serving_warmup_requests\u0026#34;): log = prediction_log_pb2.PredictionLog() log.ParseFromString(serialized_example) print(i, type(serialized_example), type(log), \u0026#34;End\u0026#34;) i += 1 print(log) break par_warmup() 文件内容包括：\nmodel_spec inputs 形状大小 数据类型 outputs predict_log { request { model_spec { name: \u0026#34;model\u0026#34; signature_name: \u0026#34;serving_default\u0026#34; } inputs { key: \u0026#34;total_cnt\u0026#34; value { dtype: DT_INT64 tensor_shape { dim { size: 1 } dim { size: 1 } } int64_val: 1 } } "},{"section":"Blog","slug":"/blog/post-2/","title":"[ICLR 2023] MASKFUSION: FEATURE AUGMENTATION FOR CLICK-THROUGH RATE PREDICTION VIA INPUT-ADAPTIVE","description":"this is meta description","date":"February 7, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"论文, 推荐算法","tags":"paper, 推荐算法","content":"摘要 这篇论文提出了一个自适应特征融合框架，称为MaskFusion，以额外捕获显式的交互分析了输入特征与现有深部CTR结构之间的关系动态建模，除了现有的共同特征的相互作用的工作原理。\nMaskFusion是一种实例级别的粒度的感知，用于对提取的信息进行增强，使深度CTR模型更加个性化，通过分配每个特征与实例自适应掩码和融合每个特征与每个隐藏状态向量深部结构。MaskFusion使用起来也比较灵活，可以集成到任何现有的深度CTR模型当中。\n模型结构 核心方法 该论文的核心方法主要有三部分，接下来会分成这三部分去说明每个组件的作用。\nFusion Layer\nMask Controller\nInstance Norm Layer\nFusion Layer Fusion Layer主要的作用就是用来与NN层进行交互，作为融合的手段，论文当中选取的方式是 Concat。论文当中的解释为，如果使用element-wise的交互方式，很难对特征的可解释性有所贡献，言下之意就是concat的方式能够比较明确将增益部分做出归属判断。\n$$\\mathbf h_t=Relu(\\mathbf W_t \\mathbf{\\hat{h}}_{t-1}+\\mathbf{b}_t)$$\n$$\\hat h_t=Concate([E,Relu(W_t\\hat{h}_{t-1}+b_t)])$$\nFusion Layer 的还有提升模型的记忆能力，但是会对所有的实例级别的数据无差别的进行融合交互，忽略掉实例之间的差异。另外就是提高了记忆能力就会降低模型的泛化能力。于是，论文就设计了第二个模块，Mask Controller。\nMask Controller Mask Controller的作用在于基于每个实例的全局信息自动生成Mask，并且在Fusion Layer的融合过程中对生成的Mask进行应用。\n这里的Mask处理意味着能够融合过程中能够进行更好的记忆，我们也能够知道哪些特征能够更好地作用于CTR预测，同时意味着具有很强的可解释性。\n在论文当中，使用MLP作为演示，用来生成Mask，公式如下：\n$$\\boldsymbol\\alpha_t^k=MLP_{\\boldsymbol\\phi_t}(\\mathbf E)$$\n注意公式中的下标，下标意味着对每个实例 $k$ 都有第 $t$ 个mask生成器，生成器的个数，与即将交互的DNN的层数相同。\n为了学习哪些特征更有助于网络记忆，以及更好地进行训练收敛，论文当中采用了 $softmax$ 的激活函数对 mask 进行normalize。\n公式如下：\n$$m_{t,j}^k=\\dfrac{exp(\\alpha_{t,j}^k)}{\\sum_{t=1}^l exp(\\alpha_{t,j}^{k})},~\\forall j\\in[1,n],~\\forall t\\in[1,l]$$\nMask生成好之后，对特征向量进行相乘，然后与主网络每层的输出进行级联，送到下一层。\n$$ \\mathbf{\\hat h_t}=Concate([\\mathbf m_t^k \\mathbf E,\\mathit Relu(\\mathbf W_t \\mathbf{\\hat h_{t-1}}+\\mathbf b_t)]) $$\nInstance Norm Layer 论文中认为，Mask的效果可能被重缩放所影响，为了消除这种现象，在消失重缩放的过程中保留每一位的信息。 Batch Norm 以及 Layer Norm 都不能适用这个问题，因为BN的计算是计算一个小批量中所有实例的信息，LN的计算是计算一个实例中所有特征的信息。\n论文当中使用了实例级别的Norm，被称为Instance Norm，公式如下：\n$$IN(\\mathbf e_j^k)=\\gamma\\cdot\\dfrac{\\mathbf e_j^k-\\mu_j}{\\sqrt{\\sigma_j^2+\\epsilon}}+\\boldsymbol\\beta$$\n这里的BN LN IN的理解，可以参考这篇文章 总结 这种方式基本上属于万金油的trick优化方式，提升Mask的准确性以及泛化性，适用于各个以DNN为基础的推荐系统，也属于比较好工程实现的方式。\n"},{"section":"Blog","slug":"/blog/post-1/","title":"2024 推荐系统论文汇总","description":"this is meta description","date":"February 5, 2024","image":null,"imageSM":null,"searchKeyword":"","categories":"推荐算法, 论文","tags":"推荐, 论文","content":"对2024年的 推荐系统论文进行一波收集，给各位初学者和算法大佬作为灵感来源，后续专栏会继续更新论文解读，根据评论不断补充，欢迎大家三连~\nAAAI 2024 转载自：https://zhuanlan.zhihu.com/p/673884610\nSparse Enhanced Network: An Adversarial Generation Method for Robust Augmentation in Sequential Recommendation Backdoor Adjustment via Group Adaptation for Debiased Coupon Recommendations Temporally and Distributionally Robust Optimization for Cold-start Recommendation Learning Accurate and Bidirectional Transformation via Dynamic Embedding Transportation for Cross-Domain Recommendation Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations Peer Learning: Learning Complex Policies in Groups from Scratch via Action Recommendations CoreRec: A Counterfactual Correlation Inference for Next Set Recommendation Enhancing Job Recommendation through LLMbased Generative Adversarial Networks Temporal Graph Contrastive Learning for Sequential Recommendation Less is More: Label Recommendation for Weakly Supervised Point Cloud Semantic Segmentation Effect Size Estimation for Duration Recommendation in Online Experiments: Leveraging Hierarchical Models and Objective Utility Approaches D3: A Methodological Exploration of Domain Division, Modeling, and Balance in Multi-Domain Recommendations STEM: Unleashing the Power of Embeddings for Multi-task Recommendation No prejudice! Fair Federated Graph Neural Networks for Personalized Recommendation Fine-tuning Large Language Model based Explainable Recommendation with Explainable Quality Reward VITA: \u0026lsquo;Carefully Chosen and Weighted Less\u0026rsquo; Is Better in Medication Recommendation A Goal Interaction Graph Planning Framework for Conversational Recommendation RRL: Recommendation Reverse Learning Dual-view Whitening on Pre-trained Text Embeddings for Sequential Recommendation Graph Disentangled Contrastive Learning with Personalized Transfer for Cross-Domain Recommendation LLMRG: Improving Recommendations through Large Language Model Reasoning Graphs Spectral-based Graph Neutral Networks for Complementary Item Recommendation LGMRec: Local and Global Graph Learning for Multimodal Recommendation Plug-in Diffusion Model for Sequential Recommendation Successive POI Recommendation via Brain-inspired Spatiotemporal Aware Representation Multi-Domain Recommendation to Attract Users via Domain Preference Modeling Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential Recommendations An Attentive Inductive Bias for Sequential Recommendation beyond the Self-Attention Distributional Off-Policy Evaluation for Slate Recommendations Review-Enhanced Hierarchical Contrastive Learning for Recommendation Preference Aware Dual Contrastive Learning for Item Cold-Start Recommendation Tail-STEAK: Improve Friend Recommendation for Tail Users via Self-Training Enhanced Knowledge Distillation Learning Time Slot Preferences via Mobility Tree for Next POI Recommendation Knowledge-Aware Explanable Reciprocal Recommendation Adaptive Hardness Negative Sampling for Collaborative Filtering Generalize for Future: Slow and Fast Trajectory learning for CTR prediction AT4CTR: Auxiliary Match Tasks for Enhancing Click-Through Rate Prediction WSDM 2024 转载自： https://zhuanlan.zhihu.com/p/665023987 Defense Against Model Extraction Attacks on Recommender Systems（南阳理工）【推荐系统攻防】 Sixiao Zhang (Nanyang Technological University)*; Hongzhi Yin (The University of Queensland); Hongxu Chen (The University of Queensland); Cheng Long (Nanyang Technological University)\nMotif-based Prompt Learning for Universal Cross-domain Recommendation（首都师范）【基于Motif的通用跨域推荐提示学习】 Bowen Hao (Captial Normal University)*; Chaoqun Yang (Griffith University); Lei Guo (Shandong Normal University); Junliang Yu (The University of Queesland); Hongzhi Yin (The University of Queensland)\nTo Copy, or not to Copy; That is a Critical Issue of the Output Softmax Layer in Neural Sequential Recommenders（亚马逊）【复制或不复制；这是神经序列推荐器中输出Softmax层的一个关键问题】 Haw-shiuan Chang (Amazon)*; Nikhil Agarwal (http://Amazon.com ); Andrew McCallum (Univ of Massachusetts Amherst)\nLinear Recurrent Units for Sequential Recommendation（伊利诺伊）【序列推荐的线性递归单元】 Zhenrui Yue (University of Illinois Urbana-Champaign); Yueqi Wang (University of California, Berkeley); Zhankui He (UC, San Diego)*; Huimin Zeng (University of Illinois at Urbana-Champaign); Julian McAuley (UCSD); Dong Wang (University of Illinois Urbana-Champaign)\nUser Behavior Enriched Temporal Knowledge Graph for Sequential Recommendation（新加坡国立，华为）【用户行为丰富知识图谱，用于序列推荐】 Hengchang Hu (National University of Singapore)*; Wei Guo (Huawei Noah’s Ark Lab); Xu Liu (National University of Singapore); Yong Liu (Huawei); Ruiming Tang (Huawei Noah’s Ark Lab); Rui Zhang (http://ruizhang.info ); Min-Yen Kan (National University of Singapore)\nIntent Contrastive Learning with Cross Subsequences for Sequential Recommendation（东吴大学）【基于跨子序列的意图对比学习序列推荐】 Xiuyuan Qin (Soochow University)*; Huanhuan Yuan (Soochow University); Pengpeng Zhao (Soochow University); Guanfeng Liu (Macquarie University); Fuzhen Zhuang (Institute of Artificial Intelligence, Beihang University); Victor S. Sheng (Texas Tech University)\nBudgeted Embedding Table For Recommender Systems（昆士兰）【推荐系统的嵌入表研究】 Yunke Qu (The University of Queensland)*; Tong Chen (The University of Queensland); Quoc Viet Hung Nguyen (Griffith University); Hongzhi Yin (The University of Queensland)\nPre-trained Recommender Systems: A Causal Debiasing Perspective（威斯康星，亚马逊）【预训练推荐系统：因果去偏的视角】 Ziqian Lin (University of Wisconsin–Madison)*; Hao Ding (AWS AI Lab); Nghia Trong Hoang (Washington State University); Branislav Kveton (AWS AI Labs); Anoop Deoras (Amazon); Hao Wang (Rutgers University)\nDynamic Sparse Learning: A Novel Paradigm for Efficient Recommendation（中科大）【动态稀疏学习：一种高效推荐的新范式】 Shuyao Wang (University of Science and Technology of China)*; Yongduo Sui (University of Science and Technology of China); Jiancan Wu (University of Science and Technology of China); Zhi Zheng (University of Science and Technology of China); Hui Xiong (Hong Kong University of Science and Tech)\nPEACE: Prototype lEarning Augmented transferable framework for Cross-domain rEcommendation（蚂蚁）【PEACE：用于跨域推荐的原型lEarning增强可迁移框架】 Chunjing Gan (Ant Group)*; Bo Huang (Ant Group); Binbin Hu (Ant Group); Jian Ma (Ant Group); Zhiqiang Zhang (Ant Group); Jun Zhou (Ant Financial); Guannan Zhang (Ant Group); WENLIANG ZHONG (Ant Group)\nMADM: A Model-agnostic Denoising Module for Graph-based Social Recommendation（上交）【MADM：一个基于图的社交推荐的模型无关去噪模块】 Wenze Ma (Shanghai Jiao Tong University)*; Yuexian Wang (Shanghai Jiao Tong University); Yanmin Zhu (Shanghai Jiao Tong University); Zhaobo Wang (Shanghai Jiao Tong University); Mengyuan Jing (Shanghai Jiao Tong University); Xuhao Zhao (Shanghai Jiao Tong University); Jiadi Yu (Shanghai Jiao Tong University); Feilong Tang (Shanghai Jiao Tong University)\nCollaboration and Transition: Distilling Item Transitions into Multi-Query Self-Attention for Sequential Recommendation（蒙特利尔，快手）【协作与转换：提取项目转换为序列推荐的多查询自注意力机制】 Tianyu Zhu (University of Montreal)*; Yansong Shi (Tsinghua University); Yuan Zhang (Kuaishou Inc.); Yihong Wu (Université de Montréal); Fengran Mo (Université de Montréal); Jian-Yun Nie (Université de Montréal)\nCDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process（中科院）【CDRNP：通过神经过程向冷启动用户提供跨领域推荐】 Xiaodong Li (Institute of Information Engineering, Chinese Academy of Sciences)*; Jiawei Sheng ( Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China); Jiangxia Cao (Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China); Tingwen Liu (Institute of Information Engineering, CAS); Wenyuan Zhang (Institute of Information Engineering, Chinese Academy of Sciences); Quangang Li (Institute of Information Engineering, CAS)\nInverse Learning with Extremely Sparse Feedback for Recommendation（卡耐基梅隆，快手）【具有极稀疏反馈的反向学习推荐】 Guanyu Lin (Carnegie Mellon University)*; Chen Gao (Tsinghua University); Yu Zheng (Tsinghua University); Yinfeng Li (Kuaishou Inc); Jianxin Chang (Kuaishou Inc); Yanan Niu (Kuaishou Inc); Yang Song (Kuaishou Technology); Kun Gai (AI); Zhiheng Li (Tsinghua University); Depeng Jin (Tsinghua University); Yong Li (Tsinghua University)\nContextual MAB Oriented Embedding Denoising for Sequential Recommendation（北邮）【面向上下文MAB的序列推荐嵌入去噪】 Zhichao Feng (Beijing University of Post and Telecommunications); Pengfei Wang (School of Computer Science, Beijing University of Posts and Telecommunications)*; Kaiyuan Li (Beijing University of Posts and Telecommunications); Chenliang Li (Wuhan University); Shangguang Wang (State Key Laboratory of Networking and Switching Technology)\nMixed Attention Network for Cross-domain Sequential Recommendation（卡耐基梅隆，快手）【跨域序列推荐的混合注意网络】 Guanyu Lin (Carnegie Mellon University)*; Chen Gao (Tsinghua University); Yu Zheng (Tsinghua University); Jianxin Chang (Kuaishou Inc); Yanan Niu (Kuaishou Inc); Yang Song (Kuaishou Technology); Kun Gai (AI); Zhiheng Li (Tsinghua University ); Depeng Jin (Tsinghua University); Yong Li (Tsinghua University); Meng Wang (Institute of Artificial Intelligence, Hefei Comprehensive National Science Center)\nKnowledge Graph Context-Enhanced Diversified Recommendation（伊利诺伊）【知识图谱上下文增强的多样化推荐】 Xiaolong Liu (University of Illinois at Chicago)*; Liangwei Yang (University of Illinois at Chicago); Zhiwei Liu (Salesforce); Mingdai Yang (University of Illinios at Chicago); Chen Wang (University of Illinois at Chicago); Hao Peng (Beihang University); Philip S Yu (UIC)\nExploring Adapter-based Transfer Learning for Recommender Systems: Empirical Studies and Practical Insights（西湖大学）【基于适配器的推荐系统迁移学习探索：实证研究与实践启示】 Junchen Fu (Westlake University)*; Fajie Yuan (Westlake University); Yu Song (Westlake University); Zheng Yuan (Westlake University); Mingyue Cheng (University of Science and Technology of China); Shenghui Cheng (Westlake University); Jiaqi Zhang (Westlake University); Jie Wang (Westlake University); Yunzhu Pan (University of Electronic Science and Technology of China)\nDiff-MSR: A Diffusion Model Enhanced Paradigm for Cold-Start Multi-Scenario Recommendation（香港城市大学，华为）【Diff-MSR：冷启动多场景推荐的扩散模型增强范式】 Yuhao Wang (City University of Hong Kong)*; Ziru Liu (City University Of HongKong ); Yichao Wang (Huawei Noah’s Ark Lab); Xiangyu Zhao (City University of Hong Kong); Bo Chen (Huawei Noah’s Ark Lab); Huifeng Guo (Huawei Noah’s Ark Lab); Ruiming Tang (Huawei Noah’s Ark Lab)\nAutoPooling: Automated Pooling Search for Multi-valued Features in Recommendations（腾讯） He Wei (Tencent Inc.)*; Meixi Liu (Machine learning platform department, Tencent TEG); Yang Zhang (Tencent Inc)\nC^2DR: Robust Cross-Domain Recommendation based on Causal Disentanglement（中南）【C^2DR：基于因果解耦的鲁棒跨域推荐】 Menglin Kong (Central South University); Jia Wang (Xi’an Jiaotong-Liverpool University)*; Yushan Pan (Xi’an Jiaotong-Liverpool University); Haiyang Zhang (Xi’an Jiaotong-Liverpool University); Muzhou Hou (Central South Uinversity) Unified Pretraining for Recommendation via Task Hypergraphs（伊利诺伊，Salesforce）【基于任务超图的推荐统一预训练】\nMingdai Yang (University of Illinios at Chicago)*; Zhiwei Liu (Salesforce); Liangwei Yang (University of Illinois at Chicago); Xiaolong Liu (University of Illinois at Chicago); Chen Wang (University of Illinois at Chicago); Hao Peng (Beihang University); Philip S Yu (UIC)\nSSLRec: A Self-Supervised Learning Library for Recommendation（港大）【自监督推荐库】 Xubin Ren (the University of Hong Kong)*; Lianghao Xia (University of Hong Kong); Yuhao Yang (Wuhan University); Wei Wei (University of Hong Kong); Tianle Wang (HKU); Xuheng Cai (The University of Hong Kong); Chao Huang (University of Hong Kong)\nMulti-Sequence Attentive User Representation Learning for Side-information Integrated Sequential Recommendation（深圳大学，腾讯）【辅助信息集成序列推荐的多序列注意用户表征学习】 Xiaolin Lin (Shenzhen University)*; Jinwei Luo (Shenzhen University); Junwei Pan (Tencent); Weike Pan (Shenzhen University); Zhong Ming (Shenzhen University); Xun Liu (Tencent); HUANG SHUDONG (tencent); Jie Jiang (Tencent Inc.)\nLabelCraft: Empowering Short Video Recommendations with Automated Label Crafting（中科大，快手）【LabelCraft：通过自动标签制作实现短视频推荐】 Yimeng Bai (University of Science and Technology of China)*; Yang Zhang (University of Science and Technology of China); Jing Lu (Kuaishou Inc); Jianxin Chang (Kuaishou Inc); Xiaoxue Zang (Kuaishou Inc); Yanan Niu (Kuaishou); Yang Song (Kuaishou Technology); Fuli Feng (University of Science and Technology of China)\nMONET: Modality-Embracing Graph Convolutional Network and Target-Aware Attention for Multimedia Recommendation（汉阳大学）【MONET：包含图卷积网络的模态和多媒体推荐的目标感知注意力】 Yungi Kim (Hanyang University); Taeri Kim (Hanyang University); Won-Yong Shin (Yonsei University, Korea); Sang-Wook Kim (Hanyang University, Korea)*\nRecJPQ: Training Large-Catalogue Sequential Recommenders【RecJPQ：训练大型目录序列推荐】 Aleksandr V Petrov (University of Glasgow); Craig Macdonald (University of Glasgow) On the Effectiveness of Unlearning in Session-Based Recommendation（山大）【基于会话的推荐中释放的有效性研究】 Xin Xin (Shandong University); Liu Yang (Shandong University); Ziqi Zhao (Shandong University); Pengjie Ren (Shandong University); Zhumin Chen (Shandong University); Jun Ma (Shandong University); Zhaochun Ren (Leiden University)\nProxy-based Item Representation for Attribute and Context-aware Recommendation（首尔国立大学）【基于代理的item表征】 Jinseok Seol (Seoul National University)*; Minseok Gang (Seoul National University); Sang-goo Lee (Seoul National University); Jaehui Park (University of Seoul)\nIncMSR: An Incremental Learning Approach for Multi-Scenario Recommendation（清华，华为）【IncMSR：一种用于多场景推荐的增量学习方法】 Kexin Zhang (Tsinghua University)*; Yichao Wang (Huawei Noah’s Ark Lab); Xiu Li (Tsinghua University); Ruiming Tang (Huawei Noah’s Ark Lab); Rui Zhang (http://ruizhang.info )\nDeep Evolutional Instant Interest Network for CTR Prediction in Trigger-Induced Recommendation（阿里）【触发推荐中CTR预测的深度进化即时兴趣网络】 Zhibo Xiao (Alibaba Group)*; Luwei Yang (Alibaba Group); Tao Zhang (Alibaba Group); Wen Jiang (Alibaba Group); Wei Ning ( Alibaba Group); Yujiu Yang (Tsinghua University)\nUser Consented Federated Recommender System Against Personalized Attribute Inference Attack Qi Hu (Hong Kong University of Science and Technology)*; Yangqiu Song (Hong Kong University of Science and Technology)\nNeural Kalman Filtering for Robust Temporal Recommendation（复旦，微软，亚马逊）【用于鲁棒时间推荐的神经卡尔曼滤波】 Jiafeng Xia (Fudan University)*; Dongsheng Li (Microsoft Research Asia); Hansu Gu (http://Amazon.com ); Tun Lu (Fudan University); Peng Zhang (Fudan University); Li Shang (Fudan University); Ning Gu (Fudan University)\nAttribute Simulation for Item Embedding Enhancement in Multi-interest Recommendation（天大）【多兴趣推荐中项目嵌入增强的属性仿真】 Yaokun Liu (Tianjin University)*; Xiaowang Zhang (Tianjin University); Minghui Zou (Tianjin University); Zhiyong Feng (Tianjin University)\nDebiasing Sequential Recommenders through Distributionally Robust Optimization over System Exposure（山大）【基于系统曝光的分布鲁棒优化对序列推荐去偏】 Jiyuan Yang (Shandong University)*; Yue Ding (Shanghai Jiao Tong University); YIDAN WANG (SHANDONG UNIVERSITY); Pengjie Ren (Shandong University); Zhumin Chen (Shandong University); Fei Cai (National University of Defense Technology); Jun Ma (Shandong University); Rui Zhang (http://ruizhang.info ); Zhaochun Ren (Leiden University); Xin Xin (Shandong University)\nKnowledge Graph Diffusion Model for Recommendation（港大）【知识图扩散模型用于推荐】 Yangqin Jiang (University of Hong Kong)*; Yuhao Yang (Wuhan University); Lianghao Xia (University of Hong Kong); Chao Huang (University of Hong Kong)\nInteract with the Explanations: Causal Debiased Explainable Recommendation System（上交，adobe）【因果去偏可解释推荐系统】 Xu Liu (Shanghai Jiao Tong University); Tong Yu (Adobe Research); Kaige Xie (Georgia Institute of Technology); Junda Wu (New York University); Shuai Li (Shanghai Jiao Tong University)*\nGlobal Heterogeneous Graph and Target Interest Denoising for Multi-behavior Sequential Recommendation（天大）【多行为序列推荐的全局异构图和目标兴趣去噪】 Xuewei Li (Tianjin University); Hongwei Chen (College of Intelligence and Computing, Tianjin University)*; Jian Yu (Tianjin University); Mankun Zhao (Tianjin University); Tianyi Xu (Tianjin University); Wenbin Zhang (Information and Network Center, Tianjin University); Mei Yu (Tianjin University) MultiFS: Automated Multi-Scenario Feature Selection in Deep Recommender Systems【MultiFS:深度推荐系统中的自动多场景特征选择】\nDugang Liu (Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University)*; Chaohua Yang (Shenzhen University); Xing Tang (Tencent); Yejing Wang (City University of Hongkong); Fuyuan Lyu (McGill University); weihong luo (tencent); Xiuqiang He (Tencent); Zhong Ming (Shenzhen University); Xiangyu Zhao (City University of Hong Kong)\nCalibration-compatible Listwise Distillation of Privileged Features for CTR Prediction（山大，阿里）【list-wise蒸馏用于CTR预测校准】 Xiaoqiang Gui (Shandong University)*; Yueyao Cheng (Alibaba Group); Xiang-Rong Sheng (Alibaba Group); Yunfeng Zhao (Shandong University); Guoxian Yu (Shandong University); Shuguang Han (Alibaba Inc.); Yuning Jiang (Alibaba Group); Jian Xu (Alibaba Group); Bo Zheng (Alibaba Group)\nICLR 2024 转载自：https://zhuanlan.zhihu.com/p/669386030\nSTUDY: Socially Aware Temporally Causal Decoder Recommender Systems 研究：社会意识时间因果解码器推荐系统\nSUBER: An RL Environment with Simulated Human Behavior for Recommender Systems SUBER：用于推荐系统的模拟人类行为的 RL 环境\nUOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems UOEP：以用户为导向的探索政策，以增强推荐系统的长期用户体验\nStrategic Recommendations for Improved Outcomes in Congestion Games 改善拥堵游戏结果的战略建议\nCategorical Features of entities in Recommendation Systems Using Graph Neural Networks 使用图神经网络的推荐系统中实体的分类特征\nSafe Collaborative Filtering 安全协同过滤\nCross-domain Recommendation from Implicit Feedback 来自隐性反馈的跨领域推荐\nDisentangled Heterogeneous Collaborative Filtering\nBe Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation 注意邻域效应：在干扰下对选择偏差进行建模以进行推荐\nDemystifying Embedding Spaces using Large Language Models\nFIITED: Fine-grained embedding dimension optimization during training for recommender systems FIITED：推荐系统训练过程中的细粒度嵌入维度优化\nFrom Deterministic to Probabilistic World: Balancing Enhanced Doubly Robust Learning for Debiased Recommendation 从确定性世界到概率性世界：平衡增强型双倍鲁棒学习以实现无偏推荐\nHow Does Message Passing Improve Collaborative Filtering? 消息传递如何改进协作过滤？\nVibeSpace: Automatic vector embedding creation for arbitrary domains and mapping between them using large language models VibeSpace：使用大型语言模型为任意域自动创建向量嵌入并在它们之间进行映射\nUnifying User Preferences and Critic Opinions: A Multi-View Cross-Domain Item-sharing Recommender System 统一用户偏好和评论家意见：一个多视角的跨域物品共享推荐系统\nGNN-based Reinforcement Learning Agent for Session-based Recommendation 基于GNN的强化学习代理，用于基于会话的推荐\nBasis Function Encoding of Numerical Features in Factorization Machines for Improved Accuracy 因式分解机中数值特征的基函数编码以提高精度\nMOESART: An Effective Sampling-based Router for Sparse Mixture of Experts MOESART：一种有效的基于采样的路由器，用于稀疏专家的混合\nOn the Embedding Collapse When Scaling up Recommendation Models 关于扩展推荐模型时的嵌入崩溃\nHyperbolic Embeddings in Sequential Self-Attention for Improved Next-Item Recommendations 顺序自注意力中的双曲线嵌入，以改进下一步建议\nConstraining Non-Negative Matrix Factorization to Improve Signature Learning 约束非负矩阵分解以改善特征学习\nFarzi Data: Autoregressive Data Distillation\nFactual and Personalized Recommendation Language Modeling with Reinforcement Learning 基于强化学习的事实和个性化推荐语言建模\nConvFormer: Revisiting Token-mixers for Sequential User Modeling ConvFormer：重新审视用于顺序用户建模的令牌混合器\nTalk like a Graph: Encoding Graphs for Large Language Models 像图形一样说话：大型语言模型的编码图形\nWeight Uncertainty in Individual Treatment Effect 个体treatment效果的权重不确定性\nExplaining recommendation systems through contrapositive perturbations 通过逆向扰动解释推荐系统\nBenchmarks for Reinforcement Learning with Biased Offline Data and Imperfect Simulators 使用有偏见的离线数据和不完美的模拟器进行强化学习的基准\nEvidential Conservative Q-Learning for Dynamic Recommendations 动态推荐的证据保守 Q 学习\nUNLEARNING THE UNWANTED DATA FROM A PERSONALIZED RECOMMENDATION MODEL 从个性化推荐模型中消除不需要的数据\nAFDGCF: Adaptive Feature De-correlation Graph Collaborative Filtering for Recommendations AFDGCF：自适应特征去相关图协同过滤推荐\n"}]