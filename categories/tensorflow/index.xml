<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tensorflow on Yao Lu</title><link>/categories/tensorflow/</link><description>Recent content in Tensorflow on Yao Lu</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 20 Mar 2024 21:00:29 +0800</lastBuildDate><atom:link href="/categories/tensorflow/index.xml" rel="self" type="application/rss+xml"/><item><title>MLIR 优化学习</title><link>/blog/post-5/</link><pubDate>Wed, 20 Mar 2024 21:00:29 +0800</pubDate><guid>/blog/post-5/</guid><description>MLIR 简介 MLIR（多级中间表示）是编译器实用工具的表示格式和库，它位于模型表示与生成硬件特定代码的低级编译器/执行器之间。</description></item><item><title>tensorflow 异步训练及其优化</title><link>/blog/post-4/</link><pubDate>Mon, 18 Mar 2024 21:00:29 +0800</pubDate><guid>/blog/post-4/</guid><description>目前遇到了 tensorflow 进行分布式训练中出现 worker 训练不均的情况，这里记录一下解决问题查找的一些资料和想法推测。</description></item><item><title>解析 tensoflow 预热文件</title><link>/blog/post-3/</link><pubDate>Mon, 26 Feb 2024 20:52:29 +0800</pubDate><guid>/blog/post-3/</guid><description>解析 tensoflow 预热文件 代码如下：</description></item></channel></rss>